{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第１章:準備運動"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "００．文字列の逆順"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "s = \"stressed\"\n",
    "\n",
    "get = \"\"\n",
    "\n",
    "get = s[::-1]\n",
    "\n",
    "print(get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "０１．「パタトクカシーー」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パトカー\n"
     ]
    }
   ],
   "source": [
    "s = \"パタトクカシー\"\n",
    "get = \"\"\n",
    "\n",
    "get = s[::2]\n",
    "\n",
    "print(get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "０２．「パトカー」＋「タクシー」＝「パタトクカシーー」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "s = \"パトカー\"\n",
    "t = \"タクシー\"\n",
    "get = \"\"\n",
    "\n",
    "for i,j in zip(s,t):\n",
    "  get += i + j\n",
    "\n",
    "print(get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "０３．円周率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n",
      "['Now', 'I', 'need', 'a', 'drink', 'alcoholic', 'of', 'course', 'after', 'the', 'heavy', 'lectures', 'involving', 'quantum', 'mechanics']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics\"\n",
    "pattern = r'[ ,]+'\n",
    "result = re.split(pattern,s)\n",
    "\n",
    "get = []\n",
    "\n",
    "for i in range(len(result)):\n",
    "  get.append(len(result[i]))\n",
    "\n",
    "print(get)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "０４．元素記号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'H', 2: 'He', 3: 'Li', 4: 'Be', 5: 'B', 6: 'C', 7: 'N', 8: 'O', 9: 'F', 10: 'Ne', 11: 'Na', 12: 'Mi', 13: 'Al', 14: 'Si', 15: 'P', 16: 'S', 17: 'Cl', 18: 'Ar', 19: 'K', 20: 'Ca'}\n"
     ]
    }
   ],
   "source": [
    "text = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can\"\n",
    "result = list(text.split())\n",
    "index = [1,5,6,7,8,9,15,16,19]\n",
    "\n",
    "get = {}\n",
    "\n",
    "for i,words in enumerate(result):\n",
    "  if ((i + 1) in index):\n",
    "    word = words[0]\n",
    "  else:\n",
    "    word = words[:2]\n",
    "  get[i + 1] = word\n",
    "\n",
    "print(get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "０５．n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "単語bi_gram:  [['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
      "文字bi_gram: ['Ia', 'am', 'ma', 'an', 'nN', 'NL', 'LP', 'Pe', 'er']\n"
     ]
    }
   ],
   "source": [
    "def n_gram(text):\n",
    "  return [text[i:i+2] for i in range(len(text) - 2 + 1)]\n",
    "\n",
    "text = \"I am an NLPer\"\n",
    "\n",
    "word_bi_gram = n_gram(list(text.split()))\n",
    "print(\"単語bi_gram: \",word_bi_gram)\n",
    "\n",
    "letter_bi_gram = n_gram(text.replace(\" \",\"\"))\n",
    "print(\"文字bi_gram:\",letter_bi_gram)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "０６．集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'paraparaparadise'bi_gram: ['pa', 'ar', 'ra', 'ap', 'pa', 'ar', 'ra', 'ap', 'pa', 'ar', 'ra', 'ad', 'di', 'is', 'se']\n",
      "'paragraph'bi_gram: ['pa', 'ar', 'ra', 'ag', 'gr', 'ra', 'ap', 'ph']\n",
      "和集合: ['gr', 'ag', 'pa', 'ap', 'ad', 'se', 'is', 'ph', 'ar', 'di', 'ra']\n",
      "積集合: ['ap', 'ar', 'pa', 'ra']\n",
      "差集合: ['is', 'di', 'ad', 'se']\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "text = \"paraparaparadise\"\n",
    "text2 = \"paragraph\"\n",
    "\n",
    "def n_gram(text):\n",
    "  return [text[i:i+2] for i in range(len(text) - 2 + 1)]\n",
    "\n",
    "text = n_gram(text.replace(\" \",\"\"))\n",
    "print(\"'paraparaparadise'bi_gram:\",text)\n",
    "\n",
    "text2 = n_gram(text2.replace(\" \",\"\"))\n",
    "print(\"'paragraph'bi_gram:\",text2)\n",
    "\n",
    "list_c = list(set(text) | set(text2))\n",
    "print(\"和集合:\",list_c)\n",
    "list_d = list(set(text) & set(text2))\n",
    "print(\"積集合:\",list_d)\n",
    "list_e = list(set(text) - set(text2))\n",
    "print(\"差集合:\",list_e)\n",
    "\n",
    "print('se' in text)\n",
    "print('se' in text2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "０７．テンプレートによる文生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "def template (x,y,z):\n",
    "  ans = f\"{x}時の{y}は{z}\"\n",
    "  return ans\n",
    "\n",
    "\n",
    "print(template(12,\"気温\",22.4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "０８．暗号文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svool\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "def chiper(text):\n",
    "    get = \"\"\n",
    "    for char in text:\n",
    "        if char.islower():\n",
    "            get += chr(219 - ord(char))\n",
    "        else:\n",
    "            get += char\n",
    "    \n",
    "    return(get)\n",
    "\n",
    "\n",
    "text = \"hello\"\n",
    "encorder = chiper(text) \n",
    "print(encorder)\n",
    "\n",
    "decorder = chiper(encorder)\n",
    "print(decorder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "０９． Typoglycemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def Typoglycemia(s):\n",
    "    get = s.split()\n",
    "    \n",
    "    result = \"\"\n",
    "    for word in get:\n",
    "        if len(word) > 4:\n",
    "            middle_chars = list(word[1:-1])\n",
    "            random.shuffle(middle_chars)\n",
    "            word = word[0] + ''.join(middle_chars) + word[-1] \n",
    "\n",
    "            result += word + ' '\n",
    "        else :\n",
    "            result += word + ' '\n",
    "\n",
    "    return result\n",
    "s = \"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "print(Typoglycemia(s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
