{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a372bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omasa/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/omasa/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from itertools import combinations\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# モデルとトークナイザーの読み込み\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model_mlm = BertForMaskedLM.from_pretrained(model_name)\n",
    "model_bert = BertModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214f4188",
   "metadata": {},
   "source": [
    "８０．トークン化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab79c6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'movie', 'was', 'full', 'of', 'inc', '##omp', '##re', '##hen', '##si', '##bl', '##lit', '##ies', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"the movie was full of incomprehensibllities.\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b387d152",
   "metadata": {},
   "source": [
    "８１．マスクの予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8708b107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "text = \"The movie was full of [MASK]\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model_mlm(**inputs)\n",
    "logits = outputs.logits\n",
    "mask_token_index = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
    "predicted_token_id = logits[0, mask_token_index].argmax(dim=-1)\n",
    "predicted_token = tokenizer.decode(predicted_token_id)\n",
    "print(predicted_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799b8b2d",
   "metadata": {},
   "source": [
    "８２．マスクのtop-k予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce42c975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: . (0.9260)\n",
      "2: ; (0.0389)\n",
      "3: ! (0.0300)\n",
      "4: ? (0.0035)\n",
      "5: ... (0.0005)\n",
      "6: | (0.0002)\n",
      "7: - (0.0001)\n",
      "8: s t u f f (0.0000)\n",
      "9: t h i n g s (0.0000)\n",
      "10: , (0.0000)\n"
     ]
    }
   ],
   "source": [
    "top_k = 10\n",
    "mask_logits = logits[0, mask_token_index, :]\n",
    "probs = F.softmax(mask_logits, dim=-1)\n",
    "topk_probs, topk_indices = torch.topk(probs, top_k, dim=-1)\n",
    "\n",
    "for i in range(top_k):\n",
    "    token = tokenizer.decode(topk_indices[0, i])\n",
    "    prob = topk_probs[0, i].item()\n",
    "    print(f\"{i+1}: {token} ({prob:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8499b900",
   "metadata": {},
   "source": [
    "８３．CLSトークンによる文ベクトル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "168cd20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix (CLS):\n",
      "[[0.9999998  0.9880608  0.95576596 0.9475324 ]\n",
      " [0.9880608  0.99999994 0.9541275  0.94866353]\n",
      " [0.95576596 0.9541275  0.99999976 0.9806931 ]\n",
      " [0.9475324  0.94866353 0.9806931  1.0000002 ]]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"The movie was full of fun.\",\n",
    "    \"The movie was full of excitement.\",\n",
    "    \"The movie was full of crap.\",\n",
    "    \"The movie was full of rubbish.\"\n",
    "]\n",
    "\n",
    "def get_cls_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model_bert(**inputs)\n",
    "    return outputs.last_hidden_state[0, 0]\n",
    "\n",
    "cls_vectors = [get_cls_embedding(sent) for sent in sentences]\n",
    "similarities = cosine_similarity(torch.stack(cls_vectors).numpy())\n",
    "\n",
    "print(\"Cosine Similarity Matrix (CLS):\")\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4558e00",
   "metadata": {},
   "source": [
    "８４．平均による文ベクトル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df03ee04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix (Avg):\n",
      "[[0.99999994 0.9981602  0.9991019  0.9980094 ]\n",
      " [0.9981602  1.         0.9963008  0.9946869 ]\n",
      " [0.9991019  0.9963008  0.9999999  0.9988854 ]\n",
      " [0.9980094  0.9946869  0.9988854  0.99999994]]\n"
     ]
    }
   ],
   "source": [
    "def get_avg_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model_bert(**inputs)\n",
    "    token_embeddings = outputs.last_hidden_state[0]\n",
    "    return token_embeddings.mean(dim=-1)\n",
    "\n",
    "avg_vectors = [get_avg_embedding(sent) for sent in sentences]\n",
    "similarities_avg = cosine_similarity(torch.stack(avg_vectors).numpy())\n",
    "\n",
    "print(\"Cosine Similarity Matrix (Avg):\")\n",
    "print(similarities_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a09134",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
